[{"path":"https://edm-developers.github.io/fastEDM/articles/chicago.html","id":"the-data","dir":"Articles","previous_headings":"","what":"The data","title":"Chicago crime/temperature example","text":"demonstrate usefulness EDM estimating impact causal variables, use real-world dataset reflects daily temperature crime levels Chicago, make available chicago.csv file. First, load time series R: Plotting two time series shows:  plotted scatter plot, appears linear correlation variables:  Calculating linear correlation Crime Temperature: shows mild correlation, however causal structure () direction shown.","code":"chicagoURL <- url(\"https://github.com/EDM-Developers/fastEDM/raw/master/vignettes/chicago.csv\") chicago <- read.csv(chicagoURL) head(chicago) #>   Time Temperature Crime #> 1    1       24.08  1605 #> 2    2       19.04  1119 #> 3    3       28.04  1127 #> 4    4       30.02  1154 #> 5    5       35.96  1251 #> 6    6       33.08  1276 library(ggplot2) #> Warning in register(): Can't find generic `scale_type` in package ggplot2 to #> register S3 method.  df <- data.frame(list(   t = rep(chicago$Time, 2),   variable = c(rep(\"Crime\", nrow(chicago)), rep(\"Temperature\", nrow(chicago))),   value = c(chicago$Crime, chicago$Temperature)))  ggplot(df, aes(x = t)) +    geom_line(aes(y = value, color = variable)) +   labs(colour = \"Time series\") ggplot(chicago, aes(x = Temperature, y=Crime)) + geom_point(color=\"#F8766D\") cor(chicago[\"Temperature\"], chicago[\"Crime\"]) #>                Crime #> Temperature 0.461996"},{"path":"https://edm-developers.github.io/fastEDM/articles/chicago.html","id":"find-the-optimal-embedding-dimension","dir":"Articles","previous_headings":"","what":"Find the optimal embedding dimension","title":"Chicago crime/temperature example","text":"Now use edm find optimal embedding dimension Temperature time series. check values \\(E = 2, \\dots 20\\). crossfold=5 option means , \\(E\\) value run 5 sets predictions, set take four fifths data training predict remaining one fifth. rho column can see prediction accuracy maximised \\(E = 7\\), take estimate embedding dimension.","code":"# Just to speed up the example chicago <- head(chicago, 2000) # TODO: Remove this later. library(fastEDM)  # Suppress the progress bar in vignettes, as it confuses knitr. formals(edm)$showProgressBar <- FALSE  edm(chicago[\"Time\"], chicago[\"Temperature\"], E=2:10, numThreads=4) #> Summary of predictions #>    E library theta       rho      mae #> 1  2     995     1 0.8813858 7.405334 #> 2  3     995     1 0.8950151 7.039877 #> 3  4     995     1 0.9008714 7.030038 #> 4  5     995     1 0.9060736 6.872606 #> 5  6     995     1 0.9082962 6.800805 #> 6  7     995     1 0.9086980 6.777308 #> 7  8     995     1 0.9091256 6.766104 #> 8  9     995     1 0.9068787 6.858237 #> 9 10     995     1 0.9065616 6.876766 #> Number of neighbours (k) is set to between  3 and 11 #> $rc #> [1] 0 #>  #> $summary #>    E library theta       rho      mae #> 1  2     995     1 0.8813858 7.405334 #> 2  3     995     1 0.8950151 7.039877 #> 3  4     995     1 0.9008714 7.030038 #> 4  5     995     1 0.9060736 6.872606 #> 5  6     995     1 0.9082962 6.800805 #> 6  7     995     1 0.9086980 6.777308 #> 7  8     995     1 0.9091256 6.766104 #> 8  9     995     1 0.9068787 6.858237 #> 9 10     995     1 0.9065616 6.876766 #>  #> $kMin #> [1] 3 #>  #> $kMax #> [1] 11 #>  #> $aggregatedSummary #>    E library theta       rho      mae #> 1  2     995     1 0.8813858 7.405334 #> 2  3     995     1 0.8950151 7.039877 #> 3  4     995     1 0.9008714 7.030038 #> 4  5     995     1 0.9060736 6.872606 #> 5  6     995     1 0.9082962 6.800805 #> 6  7     995     1 0.9086980 6.777308 #> 7  8     995     1 0.9091256 6.766104 #> 8  9     995     1 0.9068787 6.858237 #> 9 10     995     1 0.9065616 6.876766"},{"path":"https://edm-developers.github.io/fastEDM/articles/chicago.html","id":"convergent-cross-mapping","dir":"Articles","previous_headings":"","what":"Convergent cross-mapping","title":"Chicago crime/temperature example","text":"edm command can also run cross-mapping task, allows us ascertain causal links crime temperature time series. Plotting results gives:  plot, can see one direction shows significant increase accuracy \\(L\\) increases, whereas direction pretty flat. direction increases \\(\\texttt{Temperature} \\mid M(\\texttt{Crime})\\) direction. notation means used \\(\\texttt{Crime}\\) predict \\(\\texttt{Temperature}\\), due backward nature EDM means refers causal link \\(\\texttt{Temperature} \\M(\\texttt{Crime})\\). Therefore, â€™d conclude causal link temperature crime, though link reverse direction (implausible).","code":"# Find the maximum library size for the dataset. res <- edm(chicago[\"Time\"], chicago[\"Temperature\"], E=7, full=TRUE, saveManifolds=TRUE, verbosity=0) libraryMax <- nrow(res$Ms[[1]])  libs <- seq(10, libraryMax, 25)  tempPredictsCrime <- edm(chicago[\"Time\"], chicago[\"Temperature\"], chicago[\"Crime\"],                          algorithm=\"smap\", E=7, library=libs, numReps=4, numThreads=4) #> Summary of predictions #>    E library theta        rho      mae #> 1  7      10     1 0.18483952 285.4095 #> 2  7      35     1 0.06464608 295.2014 #> 3  7      60     1 0.11692195 300.7643 #> 4  7      85     1 0.12423157 277.2285 #> 5  7     110     1 0.10787778 292.2431 #> 6  7     135     1 0.07022290 316.2382 #> 7  7     160     1 0.10137296 277.2690 #> 8  7     185     1 0.11565306 274.7465 #> 9  7     210     1 0.13830563 256.8495 #> 10 7     235     1 0.10540068 251.7527 #> 11 7     260     1 0.12246767 263.2897 #> 12 7     285     1 0.11277719 273.8733 #> 13 7     310     1 0.10609714 247.8584 #> 14 7     335     1 0.10779588 270.8305 #> 15 7     360     1 0.12939396 257.0540 #> 16 7     385     1 0.12149177 257.8293 #> 17 7     410     1 0.08840150 262.7939 #> 18 7     435     1 0.12899526 261.4914 #> 19 7     460     1 0.06684048 281.4404 #> 20 7     485     1 0.14112110 261.7037 #> 21 7     510     1 0.11694683 251.3571 #> 22 7     535     1 0.12957344 259.9826 #> 23 7     560     1 0.13712296 246.5089 #> 24 7     585     1 0.08384140 301.5794 #> 25 7     610     1 0.12136025 254.1401 #> 26 7     635     1 0.14055510 247.1478 #> 27 7     660     1 0.15926516 243.5642 #> 28 7     685     1 0.10998794 255.8464 #> 29 7     710     1 0.11282903 247.5285 #> 30 7     735     1 0.16567470 243.3657 #> 31 7     760     1 0.12444390 246.0671 #> 32 7     785     1 0.11056182 251.8390 #> 33 7     810     1 0.14549500 252.1904 #> 34 7     835     1 0.12732679 241.2991 #> 35 7     860     1 0.09868812 246.2854 #> 36 7     885     1 0.15279321 243.6874 #> 37 7     910     1 0.13503642 249.5733 #> 38 7     935     1 0.14276098 249.3271 #> 39 7     960     1 0.14250497 240.8863 #> 40 7     985     1 0.13309554 243.2396 #> 41 7    1010     1 0.14091626 247.3114 #> 42 7    1035     1 0.09669331 260.0977 #> 43 7    1060     1 0.14592308 244.9345 #> 44 7    1085     1 0.13938108 242.4369 #> 45 7    1110     1 0.13767676 239.4395 #> 46 7    1135     1 0.13649138 235.6908 #> 47 7    1160     1 0.14988097 239.1891 #> 48 7    1185     1 0.12950503 249.1576 #> 49 7    1210     1 0.12982632 249.6233 #> 50 7    1235     1 0.12079033 250.2289 #> 51 7    1260     1 0.14820081 236.7330 #> 52 7    1285     1 0.13486313 238.4792 #> 53 7    1310     1 0.12505437 242.1631 #> 54 7    1335     1 0.13199944 254.9354 #> 55 7    1360     1 0.12686317 245.1241 #> 56 7    1385     1 0.14797030 241.1268 #> 57 7    1410     1 0.17608830 232.4912 #> 58 7    1435     1 0.15210785 234.0580 #> 59 7    1460     1 0.11676520 243.7742 #> 60 7    1485     1 0.14276993 243.5514 #> 61 7    1510     1 0.11385337 247.4165 #> 62 7    1535     1 0.13941205 227.2520 #> 63 7    1560     1 0.13791658 235.6425 #> 64 7    1585     1 0.14764716 229.6968 #> 65 7    1610     1 0.14054587 228.9480 #> 66 7    1635     1 0.13844549 242.1751 #> 67 7    1660     1 0.14341600 233.4059 #> 68 7    1685     1 0.13164775 237.7251 #> 69 7    1710     1 0.12461285 233.5576 #> 70 7    1735     1 0.09612660 244.4932 #> 71 7    1760     1 0.13837187 240.6580 #> 72 7    1785     1 0.08634751 252.6792 #> 73 7    1810     1 0.14192764 234.8228 #> 74 7    1835     1 0.14479947 236.9220 #> 75 7    1860     1 0.12414817 234.8049 #> 76 7    1885     1 0.13415023 236.6315 #> 77 7    1910     1 0.11627908 238.7352 #> 78 7    1935     1 0.12580231 237.2426 #> 79 7    1960     1 0.11964676 235.7624 #> 80 7    1985     1 0.12637069 238.7349 #> Number of neighbours (k) is set to  9  crimePredictsTemp <- edm(chicago[\"Time\"], chicago[\"Crime\"], chicago[\"Temperature\"],                          algorithm=\"smap\", E=7, library=libs, numReps=4, numThreads=4) #> Summary of predictions #>    E library theta       rho      mae #> 1  7      10     1 0.3642289 30.53302 #> 2  7      35     1 0.2044311 39.27714 #> 3  7      60     1 0.1575592 36.60963 #> 4  7      85     1 0.1557708 39.50634 #> 5  7     110     1 0.1901471 35.68751 #> 6  7     135     1 0.1985052 34.96056 #> 7  7     160     1 0.1990775 32.85575 #> 8  7     185     1 0.1604391 34.85910 #> 9  7     210     1 0.2066721 34.23346 #> 10 7     235     1 0.2000777 32.02932 #> 11 7     260     1 0.2013336 34.95653 #> 12 7     285     1 0.2298099 33.02414 #> 13 7     310     1 0.1675758 33.25611 #> 14 7     335     1 0.2140471 31.78329 #> 15 7     360     1 0.1740509 31.77533 #> 16 7     385     1 0.2426412 30.57438 #> 17 7     410     1 0.1851841 31.61084 #> 18 7     435     1 0.2362689 31.59864 #> 19 7     460     1 0.2564895 30.86552 #> 20 7     485     1 0.2256837 29.88678 #> 21 7     510     1 0.1753713 30.67302 #> 22 7     535     1 0.1571758 34.17882 #> 23 7     560     1 0.2063314 31.84128 #> 24 7     585     1 0.1909591 31.87472 #> 25 7     610     1 0.2138150 31.54723 #> 26 7     635     1 0.2367482 29.38815 #> 27 7     660     1 0.2392450 29.76035 #> 28 7     685     1 0.2184146 30.58127 #> 29 7     710     1 0.2121234 29.26969 #> 30 7     735     1 0.2334235 30.29931 #> 31 7     760     1 0.2389054 28.79387 #> 32 7     785     1 0.2418841 28.52921 #> 33 7     810     1 0.2515956 29.81773 #> 34 7     835     1 0.2350365 28.78420 #> 35 7     860     1 0.2229200 29.51736 #> 36 7     885     1 0.2281647 29.31747 #> 37 7     910     1 0.2457163 28.27402 #> 38 7     935     1 0.2037965 29.08109 #> 39 7     960     1 0.2082272 29.14825 #> 40 7     985     1 0.2288407 28.55651 #> 41 7    1010     1 0.2685857 27.12580 #> 42 7    1035     1 0.2115798 29.16924 #> 43 7    1060     1 0.2428661 28.00063 #> 44 7    1085     1 0.2504303 28.41482 #> 45 7    1110     1 0.2326491 28.87479 #> 46 7    1135     1 0.2330807 28.42480 #> 47 7    1160     1 0.2272694 28.33716 #> 48 7    1185     1 0.2786821 27.79291 #> 49 7    1210     1 0.2833201 27.73573 #> 50 7    1235     1 0.2720134 27.89579 #> 51 7    1260     1 0.2465089 27.79209 #> 52 7    1285     1 0.2557490 28.19913 #> 53 7    1310     1 0.2497989 28.30356 #> 54 7    1335     1 0.2341823 27.50715 #> 55 7    1360     1 0.2751412 26.85890 #> 56 7    1385     1 0.2441634 28.36577 #> 57 7    1410     1 0.2652536 27.88444 #> 58 7    1435     1 0.2408342 28.29714 #> 59 7    1460     1 0.2065951 27.89937 #> 60 7    1485     1 0.2783909 27.16609 #> 61 7    1510     1 0.2494856 27.46231 #> 62 7    1535     1 0.2788244 27.04388 #> 63 7    1560     1 0.2587217 27.43808 #> 64 7    1585     1 0.2168935 27.42739 #> 65 7    1610     1 0.2268937 28.30451 #> 66 7    1635     1 0.2675201 27.11599 #> 67 7    1660     1 0.2667839 27.19354 #> 68 7    1685     1 0.2611507 27.71664 #> 69 7    1710     1 0.2705140 27.45646 #> 70 7    1735     1 0.2779605 27.32161 #> 71 7    1760     1 0.2342103 28.70641 #> 72 7    1785     1 0.2404975 27.97711 #> 73 7    1810     1 0.2480362 27.64174 #> 74 7    1835     1 0.2742383 27.28181 #> 75 7    1860     1 0.2507781 27.86409 #> 76 7    1885     1 0.2598088 27.58648 #> 77 7    1910     1 0.2680796 27.51773 #> 78 7    1935     1 0.2810922 27.12467 #> 79 7    1960     1 0.2775581 27.23860 #> 80 7    1985     1 0.2741837 27.50466 #> Number of neighbours (k) is set to  9 <h4 class=\"card-title\">These two commands will be slow<\/h4> <p class=\"card-text\"> This selects a lot of library points, and replicates the analysis some times, so this command may take a minute or two to finish.     Choosing a machine with more CPU cores or faster cores will help significantly.    <\/p> library(tidyr)  combined <- data.frame(Library = tempPredictsCrime$aggregatedSummary$library,                        temp.to.crime = tempPredictsCrime$aggregatedSummary$rho,                        crime.to.temp = crimePredictsTemp$aggregatedSummary$rho)  tidyDF <- gather(combined, key = \"Direction\", value = \"Correlation\", -Library) tidyDF[tidyDF$Direction == \"temp.to.crime\", \"Direction\"] <- \"Crime | M(Temperature)\" tidyDF[tidyDF$Direction == \"crime.to.temp\", \"Direction\"] <- \"Temperature | M(Crime)\"  ggplot(tidyDF, aes(x = Library, y = Correlation)) +    geom_line(aes(color = Direction)) + scale_color_manual(values = c(\"darkred\", \"steelblue\")) +   geom_point(data = tempPredictsCrime$summary, aes(x = library, y = rho), alpha = 0.05, color = \"darkred\") +   geom_point(data = crimePredictsTemp$summary, aes(x = library, y = rho), alpha = 0.05, color = \"steelblue\")"},{"path":"https://edm-developers.github.io/fastEDM/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Patrick Laub. Author, maintainer. Jinjing Li. Author. Michael Zyphur. Author. Edoardo Tescari. Contributor. Simon Mutch. Contributor. George Sugihara. Originator.","code":""},{"path":"https://edm-developers.github.io/fastEDM/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Laub P, Li J, Zyphur M (2022). fastEDM: Empirical Dynamic Modeling Causal Analysis. R package version 0.1, https://edm-developers.github.io/fastEDM.","code":"@Manual{,   title = {fastEDM: Empirical Dynamic Modeling for Causal Analysis},   author = {Patrick Laub and Jinjing Li and Michael Zyphur},   year = {2022},   note = {R package version 0.1},   url = {https://edm-developers.github.io/fastEDM}, }"},{"path":"https://edm-developers.github.io/fastEDM/index.html","id":"fastedm-","dir":"","previous_headings":"","what":"Empirical Dynamic Modeling for Causal Analysis","title":"Empirical Dynamic Modeling for Causal Analysis","text":"fastEDM R package implements series Empirical Dynamic Modeling tools can used causal analysis time series data. Key features package: powered fast multi-threaded C++ backend, able process panel data, .k.. multispatial EDM, able handle missing data using new dt algorithms dropping points.","code":""},{"path":"https://edm-developers.github.io/fastEDM/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Empirical Dynamic Modeling for Causal Analysis","text":"can install development version fastEDM GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"EDM-Developers/fastEDM\")"},{"path":"https://edm-developers.github.io/fastEDM/index.html","id":"example-chicago-crime-levels-and-temperature","dir":"","previous_headings":"","what":"Example: Chicago crime levels and temperature","title":"Empirical Dynamic Modeling for Causal Analysis","text":"example, looking causal links Chicagoâ€™s temperature crime rates, described full paper:","code":"library(fastEDM) library(readr)  data <- url(\"https://raw.githubusercontent.com/EDM-Developers/EDM/master/test/chicago.csv\")  chicago <- read_csv(data, col_types = cols(crime = col_double())) chicago <- head(chicago, 500) # Just to speed up the example  crimeCCMCausesTemp <- easy_edm(\"crime\", \"temp\", data=chicago, verbosity=0) #> x No causal link from crime to temp found. tempCCMCausesCrime <- easy_edm(\"temp\", \"crime\", data=chicago, verbosity=0) #> v Strong evidence that temp causes crime."},{"path":"https://edm-developers.github.io/fastEDM/index.html","id":"stata-package","dir":"","previous_headings":"","what":"Stata Package","title":"Empirical Dynamic Modeling for Causal Analysis","text":"package R port EDM Stata package. packages share underlying C++ code, behaviour identical. plan adjust various low-level EDM parameters, check documentation Stata package details options behaviours.","code":""},{"path":"https://edm-developers.github.io/fastEDM/reference/easy_edm.html","id":null,"dir":"Reference","previous_headings":"","what":"easy_edm â€” easy_edm","title":"easy_edm â€” easy_edm","text":"easy_edm","code":""},{"path":"https://edm-developers.github.io/fastEDM/reference/easy_edm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"easy_edm â€” easy_edm","text":"","code":"easy_edm(   cause,   effect,   time = NULL,   data = NULL,   direction = \"oneway\",   verbosity = 1,   normalize = TRUE )"},{"path":"https://edm-developers.github.io/fastEDM/reference/easy_edm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"easy_edm â€” easy_edm","text":"cause first time series causal analysis effect second time series causal analysis time time uniformly sampled, must supplied . data dataframe supplied , cause, effect & time must strings containing column names relevant time series. direction string specifying whether checking one directional causal effect whether test reverse direction time. verbosity level detail output. normalize Whether normalize inputs starting EDM.","code":""},{"path":"https://edm-developers.github.io/fastEDM/reference/easy_edm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"easy_edm â€” easy_edm","text":"integer error/return code (success 0)","code":""},{"path":"https://edm-developers.github.io/fastEDM/reference/easy_edm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"easy_edm â€” easy_edm","text":"","code":"library(fastEDM)  library(readr)  data <- url(\"https://raw.githubusercontent.com/EDM-Developers/EDM/master/test/chicago.csv\")    chicago <- read_csv(data, col_types = cols(crime = col_double()))  chicago <- head(chicago, 500) # Just to speed up the example  easy_edm(\"crime\", \"temp\", data=chicago) #> â„¹ Pulling the time series from the supplied dataframe. #> â„¹ Number of observations is 500 #>  Computing: [========================================] 100% (done)                          #> âœ” Found optimal embedding dimension E to be 5. #>  Computing: [========================================] 100% (done)                          #> â„¹ The maximum library size we can use is 2475. #>  Computing: [========================================] 100% (done)                          #> â„¹ The CCM fit is (alpha, gamma, rhoInfinity) = (-0.55, 0.017, 0.61). #> âœ– No causal link from crime to temp found. #> [1] FALSE"},{"path":"https://edm-developers.github.io/fastEDM/reference/edm.html","id":null,"dir":"Reference","previous_headings":"","what":"edm â€” edm","title":"edm â€” edm","text":"edm","code":""},{"path":"https://edm-developers.github.io/fastEDM/reference/edm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"edm â€” edm","text":"","code":"edm(   t,   x,   y = c(),   panel = c(),   E = 2,   tau = 1,   theta = 1,   library = NULL,   k = 0,   algorithm = \"simplex\",   p = NULL,   crossfold = 0,   full = FALSE,   shuffle = FALSE,   copredict = c(),   savePredictions = FALSE,   saveCoPredictions = FALSE,   saveManifolds = FALSE,   saveSMAPCoeffs = FALSE,   extras = NULL,   allowMissing = FALSE,   missingDistance = 0,   dt = FALSE,   reldt = FALSE,   dtWeight = 0,   numReps = 1,   panelWeight = 0,   verbosity = 1,   showProgressBar = NA,   numThreads = 1,   lowMemory = FALSE,   predictWithPast = FALSE )"},{"path":"https://edm-developers.github.io/fastEDM/reference/edm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"edm â€” edm","text":"t time variable x first variable causal analysis y second variable causal analysis panel data panel data, variable specifies panel ID observation. E option specifies number dimensions \\(E\\) used main variable manifold reconstruction. list numbers provided, command compute results numbers specified. xmap subcommand supports single integer option whereas explore subcommand supports option numlist. default value \\(E\\) 2, theory \\(E\\) can range 2 almost half total sample size. actual \\(E\\) used estimation may different additional variables incorporated. error message provided specified value range. Missing data limit maximum \\(E\\) default deletion method. tau tau (\\(\\tau\\)) option allows researchers specify â€˜time delayâ€™, essentially sorts data multiple \\(\\tau\\). done specifying lagged embeddings take form: \\(t,t-\\tau,â€¦,t-(E-1)\\tau\\), default tau=1 (.e., typical lags). However, tau=2 set every-\\(t\\) used reconstruct attractor make predictionsâ€”halve observed sample size odd even \\(t\\) used construct set embedding vectors analysis. option helpful data oversampled (.e., spaced closely time) therefore little new information dynamic system added occasion. However, tau setting also useful different dynamics occur different times scales, can chosen reflect researcherâ€™s theory-driven interest specific time-scale (e.g., daily instead hourly). Researchers can evaluate whether \\(\\tau > 1\\) required checking large autocorrelations observed data. course, linear measure association may work well nonlinear systems thus researchers can also check performance examining \\(\\rho\\) MAE different values \\(\\tau\\). theta Theta (\\(\\theta\\)) distance weighting parameter local neighbours manifold. used detect nonlinearity system explore subcommand S-mapping. course, noted , simplex projection CCM weight theta = 1 applied neighbours based distance, reflected fact default value \\(\\theta\\) 1. However, can altered even simplex projection CCM (two cases cover ). Particularly, values S-mapping test improved predictions become local may include theta = c(0, .00001, .0001, .001, .005, .01, .05, .1, .5, 1, 1.5, 2, 3, 4, 6, 8, 10). library option specifies total library size \\(L\\) used manifold reconstruction. Varying library size used estimate convergence property cross-mapping, minimum value \\(L_{min} = E + 2\\) maximum equal total number observations minus sufficient lags (e.g., time-series case without missing data \\(L_{max} = T + 1 - E)\\). error message given \\(L\\) value beyond allowed range. assess rate convergence (.e., rate \\(\\rho\\) increases \\(L\\) grows), full range library sizes small values \\(L\\) can used, \\(E = 2\\) \\(T = 100\\), setting perhaps library = c(seq(4, 25), seq(30, 50, 5), seq(54, 99, 15)). k option specifies number neighbours used prediction. set 1, nearest neighbour used, \\(k\\) increases next-closest nearest neighbours included making predictions. case \\(k\\) set 0, number neighbours used calculated automatically (typically \\(k = E + 1\\) form simplex around target), default value. \\(k = \\infty\\) (e.g., k=Inf), possible points prediction set used (.e., points library used reconstruct manifold predict target vectors). latter setting useful typically recommended S-mapping allows points library used predictions weightings theta. However, large datasets may computationally burdensome therefore k=100 perhaps k=500 may preferred \\(T\\) \\(NT\\) large. algorithm option specifies algorithm used prediction. specified, simplex projection (locally weighted average) used. Valid options include simplex smap, latter sequential locally weighted global linear mapping (S-map noted previously). case xmap subcommand two variables predict , algorithm=\"smap\" invokes something analogous distributed lag model \\(E + 1\\) predictors (including constant term \\(c\\)) , thus, \\(E + 1\\) locally-weighted coefficients predicted observation/target vectorâ€”predicted observation type regression done \\(k\\) neighbours rows \\(E + 1\\) coefficients columns. noted , case special options available save coefficients post-processing , , actually regression model instead seen manifold. p option adjusts default number observations ahead predict. parameter can negative. crossfold option asks program run cross-fold validation predicted variables. crossfold(5) indicates 5-fold cross validation. Note used together replicate. full option specified, explore command use possible observations manifold construction instead default 50/50 split. effectively leave-one-cross-validation observation used prediction. shuffle splitting observations library prediction sets, default oldest observations go library set newest observations prediction set. Though randomize option specified, data allocated two sets random fashion. replicate option specified, randomization enabled automatically. copredict option specifies variable used coprediction. second prediction run configuration \\(E\\), library, etc., using library set prediction set built lagged embedding variable. savePredictions option allows save edm predictions useful plotting diagnosis. saveCoPredictions option allows save copredictions. must specify copredict option work. saveManifolds option allows save library prediction manifolds. saveSMAPCoeffs option allows S-map coefficients stored. extras option allows incorporating additional variables embedding (multivariate embedding), e.g. extras=c(y, z). allowMissing option allows observations missing values used manifold. Vectors least one non-missing values used manifold construction. Distance computations adapted allow missing values option specified. missingDistance option allows users specify assumed distance missing values values (including missing) estimating Euclidean distance vector. enables computations missing values. option implies allowmissing. default, distance set expected distance two random draws normal distribution, equals \\(2/\\sqrt{\\pi} \\times\\) standard deviation mapping variable. dt option allows automatic inclusion timestamp differencing embedding. \\(E\\) dt variables included embedding \\(E\\) dimensions. default, weights used additional variables equal standard deviation main mapping variable divided standard deviation time difference. can overridden dtWeight option. dt option ignored running data sampling variation time lags. first dt variable embeds time recent observation time corresponding target/predictand. reldt option, read â€˜relative dtâ€™, like dt option includes \\(E\\) extra variables embedding E dimensions. However timestamp differences added time corresponding observations, time target/predictand minus time lagged observations. dtWeight option specifies weight used timestamp differencing variable. numReps number random replications (.e. random splits library prediction sets) run. akin nonparametric bootstrap without replacement, commonly used inference using confidence intervals EDM (Tsonis et al., 2015; van Nes et al., 2015; Ye et al., 2015b). panelWeight specifies penalty added distances points manifold correspond observations different panels. default panelWeight 0, data panels mixed together treatly equally. panelWeight=Inf set weight treated \\(\\infty\\) neighbours never selected cross boundaries panels. Setting panelWeight=Inf k=Inf means may use different number neighbors different predictions (.e. panels unbalanced). verbosity level detail output. showProgressBar Whether print progress bar computations. numThreads number threads use prediction task. lowMemory lowMemory option tries save much space possible efficiently using memory, though small datasets likely slow computations small noticeable amount. predictWithPast Force predictions use contemporaneous data. Normally EDM happy cheat pulling segments future time series make prediction.","code":""},{"path":"https://edm-developers.github.io/fastEDM/reference/edm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"edm â€” edm","text":"list","code":""},{"path":"https://edm-developers.github.io/fastEDM/reference/edm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"edm â€” edm","text":"","code":"t <- c(1, 2, 3, 4, 5, 6, 7, 8)  x <- c(11, 12, 13, 14, 15, 16, 17, 18)  res <- edm(t, x) #>  Computing: [========================================] 100% (done)                          #> Summary of predictions #>   E library theta        rho     mae #> 1 2       3     1 -0.9706895 2.62881 #> Number of neighbours (k) is set to  3"},{"path":"https://edm-developers.github.io/fastEDM/reference/fastEDM.html","id":null,"dir":"Reference","previous_headings":"","what":"fastEDM â€” fastEDM","title":"fastEDM â€” fastEDM","text":"fastEDM package implements series tools can used empirical dynamic modeling. core algorithm written C++ achieve reasonable execution speed.","code":""},{"path":"https://edm-developers.github.io/fastEDM/reference/fastEDM.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"fastEDM â€” fastEDM","text":"Jinjing Li, Michael J. Zyphur, George Sugihara, Patrick J. Laub (2021), Beyond Linearity, Stability, Equilibrium: edm Package Empirical Dynamic Modeling Convergent Cross Mapping Stata, Stata Journal, 21(1), pp. 220-258","code":""},{"path":[]},{"path":"https://edm-developers.github.io/fastEDM/reference/fastEDM.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"fastEDM â€” fastEDM","text":"Patrick Laub <patrick.laub@gmail.com>","code":""},{"path":"https://edm-developers.github.io/fastEDM/reference/fastEDM.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"fastEDM â€” fastEDM","text":"","code":"library(fastEDM) library(readr)  data <- url(\"https://raw.githubusercontent.com/EDM-Developers/EDM/master/test/chicago.csv\")  chicago <- read_csv(data, col_types = cols(crime = col_double())) chicago <- head(chicago, 500) # Just to speed up the example  crimeCCMCausesTemp <- easy_edm(\"crime\", \"temp\", data=chicago, verbosity=0) #> âœ– No causal link from crime to temp found. tempCCMCausesCrime <- easy_edm(\"temp\", \"crime\", data=chicago, verbosity=0) #> âœ” Strong evidence that temp causes crime."},{"path":"https://edm-developers.github.io/fastEDM/news/index.html","id":"fastedm-01","dir":"Changelog","previous_headings":"","what":"fastEDM 0.1","title":"fastEDM 0.1","text":"Added NEWS.md file track changes package.","code":""}]
